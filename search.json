[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About this website",
    "section": "",
    "text": "This website contains the lecture slides and lab material for the guest lecture by Jelmer Poelstra (MCIC Wooster, Ohio State University) in the HCS7004 Spring 2024 course “Genome Analytics” taught by Jonathan Fresnedo-Ramirez at OSU.\nThe source code for this website can be found at https://github.com/jelmerp/HCS7004-SP24.\n\n\n\n Back to top"
  },
  {
    "objectID": "lecture.html#recap-central-dogma-omics",
    "href": "lecture.html#recap-central-dogma-omics",
    "title": "Transcriptomics with RNA-seq",
    "section": "Recap: central dogma & omics",
    "text": "Recap: central dogma & omics"
  },
  {
    "objectID": "lecture.html#the-transcriptome",
    "href": "lecture.html#the-transcriptome",
    "title": "Transcriptomics with RNA-seq",
    "section": "The transcriptome",
    "text": "The transcriptome\nThe transcriptome is the full set of transcripts expressed by an organism, which:\n\n\nIs not at all stable across time & space in any given organism\n(unlike the genome but much like the proteome)\nVaries both qualitatively (which transcripts are expressed) but especially quantitatively (how much of each transcript is expressed)"
  },
  {
    "objectID": "lecture.html#transcriptomics",
    "href": "lecture.html#transcriptomics",
    "title": "Transcriptomics with RNA-seq",
    "section": "Transcriptomics",
    "text": "Transcriptomics\nTranscriptomics is the study of the transcriptome,\ni.e. the large-scale study of RNA transcripts expressed in an organism.\n\nMany approaches & applications — but most commonly, transcriptomics focuses on:\n\n\nmRNA rather than on noncoding RNA types such as rRNA, tRNA, and miRNA\nQuantifying gene expression levels (& ignoring nucleotide-level variation)\nStatistically comparing expression between groups (treatments, populations, tissues)\n\n\n\n\n\n\nhttps://hbctraining.github.io"
  },
  {
    "objectID": "lecture.html#why-do-transcriptomics",
    "href": "lecture.html#why-do-transcriptomics",
    "title": "Transcriptomics with RNA-seq",
    "section": "Why do transcriptomics?",
    "text": "Why do transcriptomics?\nConsidering…\n\nThat protein production gives clues about the activity of specific biological functions, and the molecular mechanisms underlying those functions;\nThat it is much easier to measure transcript expression than protein expression at scale;\nThe central dogma\n\n\n… we can use gene expression levels as a proxy for protein expression levels and make functional inferences."
  },
  {
    "objectID": "lecture.html#why-do-transcriptomics-cont.",
    "href": "lecture.html#why-do-transcriptomics-cont.",
    "title": "Transcriptomics with RNA-seq",
    "section": "Why do transcriptomics? (cont.)",
    "text": "Why do transcriptomics? (cont.)\nSpecifically, we can use transcriptomics to:\n\n\nCompare & contrast phenotypic vs. molecular responses/differences\n\n\n\n\nFind the pathways and genes that:\n\nUnderlie phenotypic responses\nExplain differences between groups (treatments, genotypes, sexes, tissues, etc.)\nCan be targeted to enhance or reduce organismal responses to help control pathogens and pests"
  },
  {
    "objectID": "lecture.html#what-is-rna-seq",
    "href": "lecture.html#what-is-rna-seq",
    "title": "Transcriptomics with RNA-seq",
    "section": "What is RNA-seq?",
    "text": "What is RNA-seq?\nRNA-seq is the current state-of-the-art family of methods to study the transcriptome.\nIt involves the random sequencing of millions of transcript fragments per sample.\n\nWe will focus on the most common type of RNA-seq, which:\n\n\nDoes not actually sequence the RNA, but first reverse transcribes RNA to cDNA\nAttempts to sequence only mRNA while avoiding noncoding RNAs (“mRNA-seq”)\nDoes not distinguish between RNA from different cell types (“bulk RNA-seq”)\nUses short reads (≤150 bp) that do not cover full transcripts but do uniquely ID genes"
  },
  {
    "objectID": "lecture.html#other-rna-seq-applications",
    "href": "lecture.html#other-rna-seq-applications",
    "title": "Transcriptomics with RNA-seq",
    "section": "Other RNA-seq applications",
    "text": "Other RNA-seq applications\nRNA-seq data can also be used for applications other than expression quantification:\n\nSNP identification & analysis (for popgen, molecular evolution, functional associations)\n\n\n\nFor organisms without a reference genome: identify genes present in the organism\nFor organisms with a reference genome: discover new genes & transcripts,\nand improve genome annotation\n\n\n\n\nAll in all, RNA-seq is a very widely used technique —\nit constitutes the most common usage of high-throughput sequencing!"
  },
  {
    "objectID": "lecture.html#rna-seq-project-examples",
    "href": "lecture.html#rna-seq-project-examples",
    "title": "Transcriptomics with RNA-seq",
    "section": "RNA-seq project examples",
    "text": "RNA-seq project examples\nRNA-seq is also the most common data type I assist with as an MCIC bioinformatician. Some projects I’ve worked on used it to identify genes & pathways that differ between:\n\nMultiple soybean cultivars in response to Phytophtora sojae inoculation; soybean in response to different Phytophtora species and strains (Dorrance lab, PlantPath)\nWheat vs. Xanthomonas with a gene knock-out vs. knock-in (Jacobs lab, PlantPath)\n\n\n\nMated and unmated mosquitos (Sirot lab, College of Wooster)\nTissues of the ambrosia beetle and its symbiotic fungus (Ranger lab, USDA Wooster)\nDiapause-inducing conditions for two pest stink bug species (Michel lab, Entomology)\n\n\n\n\nHuman carcinoma cell lines with vs. without a manipulated gene (Cruz lab, CCC)\nPig coronaviruses with vs. without an experimental insertion (Wang lab, CFAH)\n\n\n\nAnd to improve the annotation of a nematode genome (Taylor lab, PlantPath)"
  },
  {
    "objectID": "lecture.html#experimental-design-groups-replicates",
    "href": "lecture.html#experimental-design-groups-replicates",
    "title": "Transcriptomics with RNA-seq",
    "section": "Experimental design: groups & replicates",
    "text": "Experimental design: groups & replicates\nRNA-seq typically compares groups of samples defined by differences in:\n\nTreatments (e.g. different host plant, temperature, diet, mated/unmated) and/or\nOrganismal variants: ages/developmental stages, sexes, or genotypes (lines/biotypes/subspecies/morphs) and/or\nTissues"
  },
  {
    "objectID": "lecture.html#experimental-design-groups-replicates-1",
    "href": "lecture.html#experimental-design-groups-replicates-1",
    "title": "Transcriptomics with RNA-seq",
    "section": "Experimental design: groups & replicates",
    "text": "Experimental design: groups & replicates\n\nhttps://github.com/ScienceParkStudyGroup/rnaseq-lesson"
  },
  {
    "objectID": "lecture.html#experimental-design-groups-replicates-2",
    "href": "lecture.html#experimental-design-groups-replicates-2",
    "title": "Transcriptomics with RNA-seq",
    "section": "Experimental design: groups & replicates",
    "text": "Experimental design: groups & replicates\nTo be able to make statistically supported conclusions about expression differences between such groups of samples, we must have biological replication.\nWhen designing an RNA-seq experiment, keep the following in mind:\n\nNumbers of replicates\nThese are typically quite low: 3 replicates per treatment (x tissue x biotype, etc.) is the most common. Not advisable to go lower — if possible, use 4 or 5 replicates.\n\n\n\nStatistical comparison design\nPreferably, keep your design relatively simple with 1-2 independent variables and 2-3 levels for each of them. Specifically, pairwise comparisons are easiest to interpret.\n\n\n\n\n\n\n\n\n\nTechnical replicates?\n\n\nYou won’t need technical replicates that only replicate library prep and/or sequencing, but depending on your experimental design, may want to technically replicate something else."
  },
  {
    "objectID": "lecture.html#from-samples-to-reads-overview-of-steps",
    "href": "lecture.html#from-samples-to-reads-overview-of-steps",
    "title": "Transcriptomics with RNA-seq",
    "section": "From samples to reads: overview of steps",
    "text": "From samples to reads: overview of steps\n\nhttps://sydney-informatics-hub.github.io/training-RNAseq-slides"
  },
  {
    "objectID": "lecture.html#rna-extraction-library-prep",
    "href": "lecture.html#rna-extraction-library-prep",
    "title": "Transcriptomics with RNA-seq",
    "section": "RNA extraction & library prep",
    "text": "RNA extraction & library prep\n\n\n\n\n\n\n\n\n\n\n\n\nLibrary preparation is typically done by sequencing facilities\n\n\n\nThere are two main ways to select for mRNAs, which make up only a few % of RNAs: poly-A selection and ribo-depletion.\n\n\n\nMany samples can be “multiplexed” into a single RNA-seq library\n\n\n\n\n\n\nFig. from Kukurba & Montgomery 2015"
  },
  {
    "objectID": "lecture.html#sequencing-considerations",
    "href": "lecture.html#sequencing-considerations",
    "title": "Transcriptomics with RNA-seq",
    "section": "Sequencing considerations",
    "text": "Sequencing considerations\n\nSequencing technology\n\nIllumina short reads: by far the most common\nPacBio or ONT long reads: consider if sequencing full transcripts (isoforms) is key\n\n\n\n\n\nSingle-end vs. paired-end reads (for Illumina)\n\nPaired-end has limited added value for reference-based, gene-level workflows (but can be key in other scenarios) — but it is still common as prices are often similar\n\n\n\n\n\n\nSequencing “depth” / amount — how many reads per sample\n\nGuidelines highly approximate (cf. in genomics) — depends not just on transcriptome size; also on expression level distribution, expression levels of genes of interest, etc.\nTypical recommendations are 20-50 million reads per sample (more for e.g. transcript-level inferences)"
  },
  {
    "objectID": "lecture.html#sequencing-depth-vs.-replicates",
    "href": "lecture.html#sequencing-depth-vs.-replicates",
    "title": "Transcriptomics with RNA-seq",
    "section": "Sequencing depth vs. replicates",
    "text": "Sequencing depth vs. replicates\nFor statistical power, more replicates are better than a higher sequencing depth:\n\n\nFig. from Liu et al. 2014"
  },
  {
    "objectID": "lecture.html#overview-of-steps",
    "href": "lecture.html#overview-of-steps",
    "title": "Transcriptomics with RNA-seq",
    "section": "Overview of steps",
    "text": "Overview of steps\n\nModified after Kukurba & Montgomery 2015"
  },
  {
    "objectID": "lecture.html#from-reads-to-counts-overview",
    "href": "lecture.html#from-reads-to-counts-overview",
    "title": "Transcriptomics with RNA-seq",
    "section": "From reads to counts: overview",
    "text": "From reads to counts: overview\nYou will typically receive a “demultiplexed” (split-by-sample) set of FASTQ files.\nOnce you receive your data, the first series of analysis steps involves going from the raw reads to a count table (which will have a read count for each gene in each sample).\n\n\nThis part is bioinformatics-heavy with large files, a need for lots of computing power such as with a supercomputer, command-line (Unix shell) programs — it specifically involves:\n\n\n\nRead preprocessing\nAligning reads to a reference genome (+ alignment QC)\nQuantifying expression levels\n\n\n\n\n\n\n\nThis can be run using standardized, one-size-fits-all workflows, and is therefore (relatively) suitable to be outsourced to a company, facility, or collaborator."
  },
  {
    "objectID": "lecture.html#reads-to-counts-read-pre-processing",
    "href": "lecture.html#reads-to-counts-read-pre-processing",
    "title": "Transcriptomics with RNA-seq",
    "section": "Reads to counts: Read pre-processing",
    "text": "Reads to counts: Read pre-processing\nRead pre-processing includes the following steps:\n\n\nChecking the quantity and quality of your reads\n\nDoes not change your data, but helps decide next steps / sample exclusion\nAlso useful to check for contamination, library complexity, and adapter content\n\n\n\n\n\nRemoving unwanted sequences\n\nAdapters, low-quality bases, and very short reads\nrRNA-derived reads (optional)\nContaminant sequences (optional)"
  },
  {
    "objectID": "lecture.html#reads-to-counts-alignment-to-a-reference-genome",
    "href": "lecture.html#reads-to-counts-alignment-to-a-reference-genome",
    "title": "Transcriptomics with RNA-seq",
    "section": "Reads to counts: alignment to a reference genome",
    "text": "Reads to counts: alignment to a reference genome\nThe alignment of reads to a reference genome needs to be “splice-aware”.\n\n\nBerge et al. 2019"
  },
  {
    "objectID": "lecture.html#reads-to-counts-alignment-to-a-reference-genome-1",
    "href": "lecture.html#reads-to-counts-alignment-to-a-reference-genome-1",
    "title": "Transcriptomics with RNA-seq",
    "section": "Reads to counts: alignment to a reference genome",
    "text": "Reads to counts: alignment to a reference genome\nAlternatively, you can align to the transcriptome (i.e., all mature transcripts):\n\nBerge et al. 2019"
  },
  {
    "objectID": "lecture.html#reads-to-counts-alignment-qc",
    "href": "lecture.html#reads-to-counts-alignment-qc",
    "title": "Transcriptomics with RNA-seq",
    "section": "Reads to counts: alignment QC",
    "text": "Reads to counts: alignment QC\n\nAlignment rates\nWhat percentage of reads was successfully aligned? (Should be &gt;80%)\n\n\n\n\nAlignment targets\nWhat percentages of aligned reads mapped to exons vs. introns vs. intergenic regions?\n\n\n\n\n\nWhat might cause high intronic mapping rates?\n\nAn abundance of pre-mRNA versus mature-mRNA.\n\n\n\n\n\nWhat might cause high intergenic mapping rates?\n\nDNA contamination or poor genome assembly/annotation quality"
  },
  {
    "objectID": "lecture.html#reads-to-counts-quantification",
    "href": "lecture.html#reads-to-counts-quantification",
    "title": "Transcriptomics with RNA-seq",
    "section": "Reads to counts: quantification",
    "text": "Reads to counts: quantification\nAt heart, a simple counting exercise once you have the alignments in hand.\nBut made more complicated by sequencing biases and multi-mapping reads.\n\n\nCurrent best-performing tools (e.g. Salmon) do transcript-level quantification — even though this is typically followed by gene-level aggregation prior to downstream analysis.\n\n\n\n\n\n\n\n\n\nFast-moving field\n\n\nSeveral very commonly used tools like FeatureCounts (&gt;15k citations) and HTSeq (&lt;18k citations) have become disfavored in the past couple of years, as they e.g. don’t count multi-mapping reads at all."
  },
  {
    "objectID": "lecture.html#a-best-practice-workflow-to-produce-counts",
    "href": "lecture.html#a-best-practice-workflow-to-produce-counts",
    "title": "Transcriptomics with RNA-seq",
    "section": "A best-practice workflow to produce counts",
    "text": "A best-practice workflow to produce counts\nThe “nf-core” initiative (https://nf-co.re) attempts to produce best-practice and automated workflows/pipelines, like for RNA-seq (https://nf-co.re/rnaseq):"
  },
  {
    "objectID": "lecture.html#count-table-analysis-overview",
    "href": "lecture.html#count-table-analysis-overview",
    "title": "Transcriptomics with RNA-seq",
    "section": "Count table analysis: overview",
    "text": "Count table analysis: overview\nThe second part of RNA-seq data analysis involves analyzing the count table.\nIn contrast to the first part, this can be done on a laptop and instead is heavier on statistics, data visualization and biological interpretation.\n\n\nIt is typically done with the R languange, and common steps include:\n\nPrincipal Component Analysis (PCA)\nAssessing overall sample clustering patterns\nDifferential Expression (DE) analysis\nFinding genes that differ in expression level between sample groups (DEGs)\nFunctional enrichment analysis\nSee whether certain gene function groupings are overrepresented among DEGs"
  },
  {
    "objectID": "lecture.html#pca",
    "href": "lecture.html#pca",
    "title": "Transcriptomics with RNA-seq",
    "section": "PCA",
    "text": "PCA\nA PCA analysis will help to visualize overall patterns of similarity among samples,\nfor example whether our groups of interest cluster:\n\n\nFig. 1 from Garrigos et al. 2023"
  },
  {
    "objectID": "lecture.html#differential-expression-de-analysis",
    "href": "lecture.html#differential-expression-de-analysis",
    "title": "Transcriptomics with RNA-seq",
    "section": "Differential expression (DE) analysis",
    "text": "Differential expression (DE) analysis\nA Differential Expression (DE) analysis allows you to test, for every single expressed gene in your dataset, whether it significantly differs in expression level between groups.\n\nTypically, this is done with pairwise comparisons between groups:"
  },
  {
    "objectID": "lecture.html#differential-expression-de-analysis-1",
    "href": "lecture.html#differential-expression-de-analysis-1",
    "title": "Transcriptomics with RNA-seq",
    "section": "Differential expression (DE) analysis",
    "text": "Differential expression (DE) analysis\nA Differential Expression (DE) analysis allows you to test, for every single expressed gene in your dataset, whether it significantly differs in expression level between groups.\nTypically, this is done with pairwise comparisons between groups:"
  },
  {
    "objectID": "lecture.html#de-analysis-general-statistical-considerations",
    "href": "lecture.html#de-analysis-general-statistical-considerations",
    "title": "Transcriptomics with RNA-seq",
    "section": "DE analysis: general statistical considerations",
    "text": "DE analysis: general statistical considerations\n\nGene count normalization\nTo be able to fairly compare samples, raw gene counts need to be adjusted:\n\nBy library size, which is the total number of gene counts per sample\nBy library composition, e.g. to correct for sample-specific extremely abundant genes that “steal” most of that sample’s counts\n\n\n\n\n\nProbability distribution of the count data\n\nGene counts have higher variance than a Poisson distribution: negative binomial distribution is typically used.\nVariance (“dispersion”) estimates are gene-specific but “borrow” information from other genes (details beyond the scope of this lecture)."
  },
  {
    "objectID": "lecture.html#de-analysis-general-statistical-considerations-cont.",
    "href": "lecture.html#de-analysis-general-statistical-considerations-cont.",
    "title": "Transcriptomics with RNA-seq",
    "section": "DE analysis: general statistical considerations (cont.)",
    "text": "DE analysis: general statistical considerations (cont.)\n\nMultiple-testing correction\n\n10,000+ genes are independently tested during a DE analysis, so there is a dire need for multiple testing correction.\nThe standard method is the Benjamini-Hochberg (BH) method.\n\n\n\n\n\nLog2-fold changes (LFC) as a measure of expression difference\n\nWe’ll discuss this in the lab.\n\n\n\n\n\n\n\n\n\n\n\nR packages to the rescue\n\n\nSpecialized R/Bioconductor packages like DESeq2 and EdgeR make differential expression analysis relatively straightforward and automatically take care of the abovementioned considerations (we will use DESeq2 in the lab)."
  },
  {
    "objectID": "lecture.html#functional-enrichment-introduction",
    "href": "lecture.html#functional-enrichment-introduction",
    "title": "Transcriptomics with RNA-seq",
    "section": "Functional enrichment: introduction",
    "text": "Functional enrichment: introduction\nLists of DEGs can be quite long, and it is not always easy to make biological sense of them. Functional enrichment analyses help with this.\nFunctional enrichment analyses check whether certain functional categories of genes are statistically overrepresented among up- and/or downregulated genes.\n\n\nThere are a number of databases that group genes into functional categories, but the two main ones used for enrichment analysis are:\n\nGene Ontology (GO)\nKyoto Encyclopedia of Genes and Genomes (KEGG)"
  },
  {
    "objectID": "lecture.html#functional-enrichment-go",
    "href": "lecture.html#functional-enrichment-go",
    "title": "Transcriptomics with RNA-seq",
    "section": "Functional enrichment: GO",
    "text": "Functional enrichment: GO\n\n\n\nGenes are assigned zero, one or more GO “terms”\nHierarchical structure with more specific terms grouping into more general terms\nHighest-level grouping are the three “ontologies”: Biological Process, Molecular Function, Cellular Component\n\n\n\nFig. 4 from Garrigos et al. 2023"
  },
  {
    "objectID": "lecture.html#functional-enrichment-kegg",
    "href": "lecture.html#functional-enrichment-kegg",
    "title": "Transcriptomics with RNA-seq",
    "section": "Functional enrichment: KEGG",
    "text": "Functional enrichment: KEGG\nKEGG focuses on pathways for cellular and organismal functions whose genes can be drawn and connected in maps.\n\n\n\n\n\n\n\nRodriguez et al. 2020: “KEGG representation of up-regulated genes related to jasmonic acid (JA) signal transduction pathways (ko04075) in banana cv. Calcutta 4 after inoculation with Pseudocercospora fijiensis. Genes or chemicals up-regulated at any time point were highlighted in green.”"
  },
  {
    "objectID": "lecture.html#functional-enrichment-kegg-1",
    "href": "lecture.html#functional-enrichment-kegg-1",
    "title": "Transcriptomics with RNA-seq",
    "section": "Functional enrichment: KEGG",
    "text": "Functional enrichment: KEGG\n\nRodriguez et al. 2020"
  },
  {
    "objectID": "lab1.html",
    "href": "lab1.html",
    "title": "Lab part I: nf-core workflow",
    "section": "",
    "text": "This page is still under construction"
  },
  {
    "objectID": "lab1.html#setting-up",
    "href": "lab1.html#setting-up",
    "title": "Lab part I: nf-core workflow",
    "section": "1 Setting up",
    "text": "1 Setting up\n\n1.1 Getting started with VS Code\nWe will use the VS Code text editor to write a script to run the nf-core rnaseq worklow. To emphasize the additional functionality relative to basic text editors like Notepad and TextEdit, editors like VS Code are also referred to as “IDEs”: Integrated Development Environments. The RStudio program is another good example of an IDE. Just like RStudio is an IDE for R, VS Code will be our IDE for shell code today.\n\nStarting VS Code at OSC\n\nLog in to OSC’s OnDemand portal at https://ondemand.osc.edu.\nIn the blue top bar, select Interactive Apps and near the bottom, click Code Server.\nVS Code runs on a compute node so we have to fill out a form to make a reservation for one:\n\nThe OSC “Project” that we want to bill for the compute node usage: PAS2658.\nThe “Number of hours” we want to make a reservation for: 2.\nThe “Working Directory” for the program: your personal folder in /fs/scratch/PAS2658 (e.g. /fs/scratch/PAS2658/jelmer).\nThe “Codeserver Version”: 4.8 (most recent).\n\nClick Launch.\nFirst, your job will be “Queued” — that is, waiting for the job scheduler to allocate compute node resources to it.\nYour job is typically granted resources within a few seconds (the card will then say “Starting”), and should be ready for usage (“Running”) in another couple of seconds.\nOnce it appears, click on the blue Connect to VS Code button to open VS Code in a new browser tab.\nWhen VS Code opens, you may get these two pop-ups (and possibly some others) — click “Yes” (and check the box) and “Don’t Show Again”, respectively:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nYou’ll also get a Welcome/Get Started page — you don’t have to go through steps that may be suggested there.\n\n\n\n\nThe VS Code User Interface\n\n\nClick to see a screenshot\n\n\n\n\nSide bars\nThe Activity Bar (narrow side bar) on the far left has:\n\nA  (“hamburger menu”), which has menu items like File that you often find in a top bar.\nA  (cog wheel icon) in the bottom, through which you can mainly access settings.\nIcons to toggle between (wide/Primary) Side Bar options, like a File Explorer (the default option), Search, and Version Control.\n\n\n\nTerminal\nOpen a terminal with a Unix shell by clicking    =&gt; Terminal =&gt; New Terminal. In the terminal, create a directory for this lab, e.g.:\n# You should be in your personal dir in /fs/scratch/PAS2658\npwd\n/fs/scratch/PAS2658/jelmer\nmkdir -p Lab9 \ncd Lab9\nmkdir scripts run software\n\n\nEditor pane and Welcome document\nThe main part of the VS Code is the editor pane. Here, we can open files like scripts and other types of text files, and images. Let’s create and save a new file:\n\nOpen a new file: Click the hamburger menu , then File &gt; New File.\nSave the file (Ctrl/⌘+S), inside one of the dirs you just created: Lab9/scripts/run.sh.\n\n\n\n\n\n\n\nA folder as a starting point (Click to expand)\n\n\n\n\n\nConveniently, VS Code takes a specific directory as a starting point in all parts of the program:\n\nIn the file explorer in the side bar\nIn the terminal\nWhen saving files in the editor pane.\n\nThis is why your terminal was “already” located in /fs/scratch/PAS2658/&lt;your-name&gt;.\nIf you need to switch folders, click      &gt;   File   &gt;   Open Folder.\n\n\n\n\n\n\n\n\n\nHow to hide the side bars (Click to expand)\n\n\n\n\n\nIf you want to save some screen space while coding along in class, you may want to occasionally hide the side bars:\n\nIn  &gt; View &gt; Appearance you can toggle both the Activity Bar and the Primary Side Bar.\nOr use keyboard shortcuts:\n\nCtrl/⌘+B for the primary/wide side bar\nCtrl+Shift+B for the activity/narrow side bar\n\n\n\n\n\n\n\n\n\n\n\nSome VS Code tips and tricks (Click to expand)\n\n\n\n\n\n\nResizing panes\nYou can resize panes (terminal, editor, side bar) by hovering your cursor over the borders and then dragging.\nThe Command Palette\nTo access all the menu options that are available in VS Code, the so-called “Command Palette” can be handy, especially if you know what you are looking for. To access the Command Palette, click      and then Command Palette (or press F1 or Ctrl/⌘+Shift+P). To use it, start typing something to look for an option.\nKeyboard shortcuts\nFor a single-page PDF overview of keyboard shortcuts for your operating system:    =&gt;   Help   =&gt;   Keyboard Shortcut Reference. (Or for direct links to these PDFs: Windows / Mac / Linux.) A couple of useful keyboard shortcuts are highlighted below.\n\n\n\n\n\n\n Exercise: Install the Shellcheck extension\nClick the gear icon  and then Extensions, and search for and then install the shellcheck (by simonwong) extension, which will check your shell scripts for errors and is extremely useful.\n\n\n\n\n\n1.2 Script setup\nWe will be working with two scripts in this lab:\n\nA “runner” script that you can also think of as a digital lab notebook, containing commands that we run interactively. This is the run/run.sh script you already created.\nA script that we will submit as a Slurm batch job with sbatch, containing code to run the nf-core nextflow workflow. We will save that as scripts/nfc-rnaseq.sh:\n# Create an empty file - this will be our batch job script \ntouch scripts/nfc-rnaseq.sh\n\n\n\n\n1.3 Activate the Conda environment\nTo save some time, you won’t do your own Conda installation of Nextflow or nf-core tools — I’ve installed both of these in an environment that you can activate as follows:\n# First load OSC's (mini)Conda module\nmodule load miniconda3\n# Then activate the Nextflow conda environment \nsource activate /fs/ess/PAS0471/jelmer/conda/nextflow\nCheck the versions:\nnextflow -v\nnextflow version 23.10.1.5891\nnf-core --version\n                                          ,--./,-.\n          ___     __   __   __   ___     /,-._.--~\\\n    |\\ | |__  __ /  ` /  \\ |__) |__         }  {\n    | \\| |       \\__, \\__/ |  \\ |___     \\`-._,-`-,\n                                          `._,._,'\n\n    nf-core/tools version 2.13.1 - https://nf-co.re\n\nnf-core, version 2.13.1"
  },
  {
    "objectID": "lab1.html#download-the-nf-core-rnaseq-workflow",
    "href": "lab1.html#download-the-nf-core-rnaseq-workflow",
    "title": "Lab part I: nf-core workflow",
    "section": "2 Download the nf-core rnaseq workflow",
    "text": "2 Download the nf-core rnaseq workflow\nWe will first set the environment variable NXF_SINGULARITY_CACHEDIR to tell Nextflow where to store the Singularity containers for all the tools that the workflow runs. More commonly, these kinds of settings are specified with options (think, e.g., --cachedir) when you run commands, but somewhat oddly, this is the only way we can specify that here.\nexport NXF_SINGULARITY_CACHEDIR=/fs/ess/PAS0471/containers\nNext, we’ll run the nf-core download command to download the currently latest version (3.14.0) of the rnaseq workflow to software/rnaseq, and the associated container files to the previously specified dir:\nnf-core download rnaseq \\\n    --revision 3.14.0 \\\n    --outdir software/nfc-rnaseq \\\n    --compress none \\\n    --container-system singularity \\\n    --container-cache-utilisation amend \\\n    --download-configuration\n\n\n\n\n\n\n\n\n\n\n\nExplanation of all options given to nf-core download (Click to expand)\n\n\n\n\n\n\n--revision: The version of the rnaseq workflow\n--outdir: The dir to save the workflow definition files\n--compress: Whether to compress the workflow files — we chose not to\n--container-system: The type of containers to download. This should always be singularity at OSC, because that’s the only supported type.\n--container-cache-utilisation: This is a little technical and not terribly interesting, but with amend, as we ran it, the process will check this dir for existing containers and simply download any that aren’t already found there.\n--download-configuration: This will download some configuration files that we will actually not use, but if you don’t provide this option it will ask you about it when you run the command."
  },
  {
    "objectID": "lab1.html#write-a-script-to-run-the-workflow",
    "href": "lab1.html#write-a-script-to-run-the-workflow",
    "title": "Lab part I: nf-core workflow",
    "section": "3 Write a script to run the workflow",
    "text": "3 Write a script to run the workflow\n\nPrepare the samplesheet\n\n\nDownload the OSC configuration file\n\n\nThe #SBATCH options\n#SBATCH --account=PAS2658\n#SBATCH --cpus-per-task=1\n#SBATCH --time=12:00:00\n#SBATCH --mail-type=END,FAIL\n#SBATCH --output=slurm-nfc_rnaseq-%j.out\n\n\nThe final command\nnextflow run software/nfcore-rnaseq/3_14_0 \\\n    --input \"$samplesheet\" \\\n    --fasta \"$fasta\" \\\n    --gtf \"$gtf\" \\\n    --outdir \"$outdir\" \\\n    --remove_ribo_rna \\\n    --extra_salmon_quant_args \"'--gcBias'\" \\\n    -resume \\\n    -profile singularity \\\n    -ansi-log false \\\n    -work-dir /fs/scratch/PAS2658/Lab9/nfc-rnaseq/\"$USER\" \\\n    -c config/osc.config\n\n\nThe final script"
  },
  {
    "objectID": "lab1.html#run-the-workflow",
    "href": "lab1.html#run-the-workflow",
    "title": "Lab part I: nf-core workflow",
    "section": "4 Run the workflow",
    "text": "4 Run the workflow\nWe will now switch back to the run/run.sh script to add the code to actually run the workflow.\n\nThe reference genome files\nref_fna=data/ref/GCF_016801865.2.fna\nref_gtf=data/ref/GCF_016801865.2.gtf\nsbatch scripts/nfc_rnaseq.sh \\\n    metadata/nfc_samplesheet.csv \\\n    \"$ref_fna\" \\\n    \"$ref_gtf\" \\\n    results/nfc_rnaseq"
  },
  {
    "objectID": "lab2.html",
    "href": "lab2.html",
    "title": "Lab part II: differential expression analysis",
    "section": "",
    "text": "This page is still under construction\nAfter running steps like read preprocessing, alignment, and quantification using the nf-core rnaseq workflow, or another method, you will have a gene count table. Today, with that gene count table, you will:"
  },
  {
    "objectID": "lab2.html#getting-set-up",
    "href": "lab2.html#getting-set-up",
    "title": "Lab part II: differential expression analysis",
    "section": "1 Getting set up",
    "text": "1 Getting set up\n\n1.1 Start an RStudio session at OSC\n\nLog in to OSC at https://ondemand.osc.edu\nClick on Interactive Apps (top bar) and then RStudio Server (all the way at the bottom)\nFill out the form as follows:\n\nCluster: Pitzer\nR version: 4.3.0\nProject: PAS2658\nNumber of hours: 3\nNode type: any\nNumber of cores: 2\n\nClick the big blue Launch button at the bottom.\nNow, you should be sent to a new page with a box at the top for your RStudio Server “job”, which should initially be “Queued” (waiting to start).\n\n\n\nClick to see a screenshot\n\n\n\n\nYour job should start running very soon, with the top bar of the box turning green and saying “Running”.\nClick Connect to RStudio Server at the bottom of the box, and an RStudio Server instance will open in a new browser tab. You’re ready to go!\n\n\n\n\n\n\n\n\nOptional: change two settings\n\n\n\n\n\nFirst, prevent R from saving your “Workspace”:\n\nClick Tools (top bar, below your browser’s address bar) &gt; Global Options\nIn the pop-up window (stay on the General tab), change the settings under the “Workspace” heading to:\n\n\n\n\n\n\nWhy are we doing this? In short, the default behavior of saving and restoring your “Workspace”, which are all the items (objects) that you create during an R session, is bad practice. Instead, you should recreate your environment from a script and/or saved files with individual pieces of data, as we’ll do today.\n\nSecond, “update” your pipe symbol from %&gt;% 1 to |&gt; 2:\n\nAgain click Tools &gt; Global Options (you may still be there)\nNow go to Code tab in the side panel on the left, and check the box for Use native pipe operator, |&gt; (requires R 4.1+)\nClick OK at the bottom of the pop-up window\n\n\n\n\n\n\n\n\n\n\n\n\n1.2 Create a new RStudio Project\nUsing an “RStudio Project” will most of all help to make sure your working directory in R is correct. To create a new RStudio Project inside your personal dir in /fs/scratch/PAS2658/&lt;your-name&gt;/Lab6:\n\nClick File (top bar, below your browser’s address bar) &gt; New Project\nIn the popup window, click Existing Directory.\n\n\n\nClick to see a screenshot\n\n\n\n\n\n\n\n\n\nClick Browse... to select your personal dir.\n\n\n\nClick to see a screenshot\n\n\n\n\n\n\n\n\nIn the next window, you should be in your Home directory (abbreviated as ~), from which you can’t click your way to /fs/scratch! Instead, you’ll first have to click on the (very small!) ... highlighted in the screenshot below:\n\n\n\n\n\n\n\nType at least part of the path to your dir in /fs/scratch/PAS2658, e.g. as shown below, and click OK:\n\n\n\n\n\n\n\nNow you should be able to browse/click the rest of the way to your personal directory.\nClick Choose to pick your selected directory.\nClick Create Project.\n\n\n\n\n1.3 Create an R script\nWe’re going to write all our code in an R script instead of typing it in the console. This helps us to keep track of what we’ve been doing, and enables us to re-run our code after modifying input data or one of the lines of code.\nCreate and open a new R script by clicking File (top menu bar) &gt; New File &gt; R Script. Save this new script right away by clicking File &gt; Save As, and save it with a name like DE.R (inside the Lab6 dir which should be automatically selected).\n\n\n\n\n\n\nMake sure to type all the R code below inside your script, and then send it to the console from there.\n\n\n\nYou can send code to the console by pressing Ctrl + Enter on Windows, or Cmd + Return on a Mac.\n\n\n\n\n\n1.4 Load the necessary packages\nIn R, we need to install and then use “packages” (basically, add-ons) to perform specialized tasks like differential expression analysis3. Installing packages is quite straightforward in principle, but in RStudio Server at OSC, there can be some hickups.\nI have therefore created a “library” (a directory with a collection of packages) for you — you can load the packages from that library, without needing to install them yourself. Copy the code below into your R script and then send it to the R console:\n\n# First, we define the dir that has the custom library:\ndyn.load(\"/fs/ess/PAS0471/jelmer/software/GLPK/lib/libglpk.so.40\", local = FALSE)\ncustom_library &lt;- \"/fs/ess/PAS0471/jelmer/R/rnaseq\"\n.libPaths(custom_library)\n\n# Then, we load all needed R packages from that library:\nlibrary(tidyverse)          # Misc. data manipulation and plotting\nlibrary(pheatmap)           # Heatmap plot\nlibrary(EnhancedVolcano)    # Volcano plot\nlibrary(DESeq2)             # Differential expression analysis\n\n\n\nThis will produce output in the R console (a lot when loading DESeq2), and some of it in orange, but all should be good unless you see explicit errors at the bottom (Click to see expected output)\n\n\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.0     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\n\nlibrary(pheatmap)\n\n\nlibrary(EnhancedVolcano)\n\nLoading required package: ggrepel\n\n\n\nlibrary(DESeq2)\n\nLoading required package: S4Vectors\n\n\nLoading required package: stats4\n\n\nLoading required package: BiocGenerics\n\n\n\nAttaching package: 'BiocGenerics'\n\n\nThe following objects are masked from 'package:lubridate':\n\n    intersect, setdiff, union\n\n\nThe following objects are masked from 'package:dplyr':\n\n    combine, intersect, setdiff, union\n\n\nThe following objects are masked from 'package:stats':\n\n    IQR, mad, sd, var, xtabs\n\n\nThe following objects are masked from 'package:base':\n\n    anyDuplicated, aperm, append, as.data.frame, basename, cbind,\n    colnames, dirname, do.call, duplicated, eval, evalq, Filter, Find,\n    get, grep, grepl, intersect, is.unsorted, lapply, Map, mapply,\n    match, mget, order, paste, pmax, pmax.int, pmin, pmin.int,\n    Position, rank, rbind, Reduce, rownames, sapply, setdiff, sort,\n    table, tapply, union, unique, unsplit, which.max, which.min\n\n\n\nAttaching package: 'S4Vectors'\n\n\nThe following objects are masked from 'package:lubridate':\n\n    second, second&lt;-\n\n\nThe following objects are masked from 'package:dplyr':\n\n    first, rename\n\n\nThe following object is masked from 'package:tidyr':\n\n    expand\n\n\nThe following object is masked from 'package:utils':\n\n    findMatches\n\n\nThe following objects are masked from 'package:base':\n\n    expand.grid, I, unname\n\n\nLoading required package: IRanges\n\n\n\nAttaching package: 'IRanges'\n\n\nThe following object is masked from 'package:lubridate':\n\n    %within%\n\n\nThe following objects are masked from 'package:dplyr':\n\n    collapse, desc, slice\n\n\nThe following object is masked from 'package:purrr':\n\n    reduce\n\n\nLoading required package: GenomicRanges\n\n\nLoading required package: GenomeInfoDb\n\n\nLoading required package: SummarizedExperiment\n\n\nLoading required package: MatrixGenerics\n\n\nLoading required package: matrixStats\n\n\n\nAttaching package: 'matrixStats'\n\n\nThe following object is masked from 'package:dplyr':\n\n    count\n\n\n\nAttaching package: 'MatrixGenerics'\n\n\nThe following objects are masked from 'package:matrixStats':\n\n    colAlls, colAnyNAs, colAnys, colAvgsPerRowSet, colCollapse,\n    colCounts, colCummaxs, colCummins, colCumprods, colCumsums,\n    colDiffs, colIQRDiffs, colIQRs, colLogSumExps, colMadDiffs,\n    colMads, colMaxs, colMeans2, colMedians, colMins, colOrderStats,\n    colProds, colQuantiles, colRanges, colRanks, colSdDiffs, colSds,\n    colSums2, colTabulates, colVarDiffs, colVars, colWeightedMads,\n    colWeightedMeans, colWeightedMedians, colWeightedSds,\n    colWeightedVars, rowAlls, rowAnyNAs, rowAnys, rowAvgsPerColSet,\n    rowCollapse, rowCounts, rowCummaxs, rowCummins, rowCumprods,\n    rowCumsums, rowDiffs, rowIQRDiffs, rowIQRs, rowLogSumExps,\n    rowMadDiffs, rowMads, rowMaxs, rowMeans2, rowMedians, rowMins,\n    rowOrderStats, rowProds, rowQuantiles, rowRanges, rowRanks,\n    rowSdDiffs, rowSds, rowSums2, rowTabulates, rowVarDiffs, rowVars,\n    rowWeightedMads, rowWeightedMeans, rowWeightedMedians,\n    rowWeightedSds, rowWeightedVars\n\n\nLoading required package: Biobase\n\n\nWelcome to Bioconductor\n\n    Vignettes contain introductory material; view with\n    'browseVignettes()'. To cite Bioconductor, see\n    'citation(\"Biobase\")', and for packages 'citation(\"pkgname\")'.\n\n\n\nAttaching package: 'Biobase'\n\n\nThe following object is masked from 'package:MatrixGenerics':\n\n    rowMedians\n\n\nThe following objects are masked from 'package:matrixStats':\n\n    anyMissing, rowMedians\n\n\n\n\n\n\n1.5 Define our input files\nFor the differential expression analysis, we have the following input files:\n\nMetadata table — Metadata for the study, linking sample IDs to treatments\nGene count table — Produced by nf-core rnaseq workflow\n\n\n# We'll save the paths to our input files for later use\n# ('..' goes up one dir in the dir hierarchy - same as in the Unix shell) \ncount_table_file &lt;- \"../share/results/counts/salmon.merged.gene_counts_length_scaled.tsv\"\nmetadata_file &lt;- \"../share/data/meta/metadata.tsv\""
  },
  {
    "objectID": "lab2.html#create-a-deseq2-object",
    "href": "lab2.html#create-a-deseq2-object",
    "title": "Lab part II: differential expression analysis",
    "section": "2 Create a DESeq2 object",
    "text": "2 Create a DESeq2 object\nLike in the Culex paper whose data we are working with, we will perform a Principal Component Analysis (PCA) and a Differential Expression (DE) analysis using the popular DESeq2 package (paper, website).\nThe DESeq2 package has its own “object type” (a specific R format type) and before we can do anything else, we need to create a DESeq2 object from three components:\n\nMetadata\nOur independent variables should be in the metadata, allowing DESeq2 to compare groups of samples.\nCount table\nA matrix (table) with one row per gene, and one column per sample.\nA statistical design\nA statistical design formula (basically, which groups to compare) will tell DESEq2 how to analyze the data\n\n\n\n2.1 Metadata\nFirst, we’ll load the metadata file and take a look at the resulting dataframe:\n\n# Read in the count table\nmeta_raw &lt;- read_tsv(metadata_file, show_col_types = FALSE)\n\n\n# Take a look at the first 6 rows\nhead(meta_raw)\n\n# A tibble: 6 × 3\n  sample_id   time  treatment  \n  &lt;chr&gt;       &lt;chr&gt; &lt;chr&gt;      \n1 ERR10802882 10dpi cathemerium\n2 ERR10802875 10dpi cathemerium\n3 ERR10802879 10dpi cathemerium\n4 ERR10802883 10dpi cathemerium\n5 ERR10802878 10dpi control    \n6 ERR10802884 10dpi control    \n\n\nWe’ll make sure the data frame is sorted by sample ID, and that the sample IDs are contained in “row names”:\n\nmeta &lt;- meta_raw |&gt;\n  # 1. Sort by the 'sample_id' column\n  arrange(sample_id) |&gt;\n  # 2. Turn the 'sample_id' column into row names:\n  column_to_rownames(\"sample_id\") |&gt;\n  # 3. Turn the 'time' and 'treatment' columns into \"factors\":\n  mutate(time = factor(time, levels = c(\"24hpi\", \"10dpi\")),\n         treatment = factor(treatment, levels = c(\"control\", \"cathemerium\", \"relictum\")))\n\n\n# Take a look at the first 6 rows\nhead(meta)\n\n             time   treatment\nERR10802863 24hpi     control\nERR10802864 24hpi cathemerium\nERR10802865 24hpi    relictum\nERR10802866 24hpi     control\nERR10802867 24hpi cathemerium\nERR10802868 24hpi    relictum\n\n\n\n\n\n\n\n\nIn the two outputs above, note the difference between having the sample IDs as a separate column versus as row names.\n\n\n\n\n\n\n\n\n\nFactors are a common R data type for categorical variables (Click to expand)\n\n\n\n\n\nWe changed the two independent variable columns (time and treatment) into factors, because DESEq2 wants this — this also allowed us to use a custom, non-alphanumeric ordering where 24hpi comes before 10dpi:\n\nhead(meta$time)\n\n[1] 24hpi 24hpi 24hpi 24hpi 24hpi 24hpi\nLevels: 24hpi 10dpi\n\n\n\n\n\n\n\n\n2.2 Gene count table\nSecond, load the gene count table into R:\n\n# Read in the count table\ncount_df &lt;- read_tsv(count_table_file, show_col_types = FALSE)\n\n\n# Take a look at the first 6 rows\nhead(count_df)\n\n# A tibble: 6 × 24\n  gene_id gene_name ERR10802863 ERR10802864 ERR10802865 ERR10802866 ERR10802867\n  &lt;chr&gt;   &lt;chr&gt;           &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt;\n1 ATP6    ATP6         10275.       8255.       4103.      18615.      11625.  \n2 ATP8    ATP8             3.85        2.92        2.33        7.76        7.01\n3 COX1    COX1         88041.      83394.      36975.     136054.     130863.  \n4 COX2    COX2          8749.       7925.       2901.      16802.      10026.  \n5 COX3    COX3         55772.      50312.      35074.      80510.      69850.  \n6 CYTB    CYTB         38543.      36352.      22185.      62147.      57461.  \n# ℹ 17 more variables: ERR10802868 &lt;dbl&gt;, ERR10802869 &lt;dbl&gt;, ERR10802870 &lt;dbl&gt;,\n#   ERR10802871 &lt;dbl&gt;, ERR10802874 &lt;dbl&gt;, ERR10802875 &lt;dbl&gt;, ERR10802876 &lt;dbl&gt;,\n#   ERR10802877 &lt;dbl&gt;, ERR10802878 &lt;dbl&gt;, ERR10802879 &lt;dbl&gt;, ERR10802880 &lt;dbl&gt;,\n#   ERR10802881 &lt;dbl&gt;, ERR10802882 &lt;dbl&gt;, ERR10802883 &lt;dbl&gt;, ERR10802884 &lt;dbl&gt;,\n#   ERR10802885 &lt;dbl&gt;, ERR10802886 &lt;dbl&gt;\n\n\nAgain, we have to make several modifications before we can include it in the DESeq2 object. DESeq2 expects with whole numbers (integers) and with gene IDs as row names:\n\n# Prepare the count table so it can be loaded into DESeq2\ncount_mat &lt;- count_df |&gt;\n  # 1. Turn the 'gene_id' column into row names:\n  column_to_rownames(\"gene_id\") |&gt;\n  # 2. Remove a remaining non-numeric column (which has gene names):\n  select(-gene_name) |&gt;\n  # 3. Round everything to whole numbers:\n  round() |&gt;\n  # 4. Convert it to a formal 'matrix' format:\n  as.matrix()\n\n\n# Take a look at the first 6 rows\nhead(count_mat)\n\n     ERR10802863 ERR10802864 ERR10802865 ERR10802866 ERR10802867 ERR10802868\nATP6       10275        8255        4103       18615       11625        7967\nATP8           4           3           2           8           7           2\nCOX1       88041       83394       36975      136054      130863       62279\nCOX2        8749        7925        2901       16802       10026        6701\nCOX3       55772       50312       35074       80510       69850       42478\nCYTB       38543       36352       22185       62147       57461       28159\n     ERR10802869 ERR10802870 ERR10802871 ERR10802874 ERR10802875 ERR10802876\nATP6       12788        4408       13648       13834        1346       10032\nATP8           2           0           2           1           3           2\nCOX1      109596      106402      104394       77682       38276       78290\nCOX2       11494        6603       11151        9893        1473       13146\nCOX3       68228       71945       66900       52368       14665       37275\nCYTB       46219       52035       46090       35247       17449       38762\n     ERR10802877 ERR10802878 ERR10802879 ERR10802880 ERR10802881 ERR10802882\nATP6         987        1834        3337        5036        1983       11586\nATP8           0           0           0           3           0          27\nCOX1       17785       32099       64490       63960       50965       76113\nCOX2        1141        1907        3439        8334        2063       12752\nCOX3        8797       15948       26278       29997       17802       35419\nCYTB       11177       22262       34368       33401       25854       43912\n     ERR10802883 ERR10802884 ERR10802885 ERR10802886\nATP6       18821        2792       11749        6682\nATP8          40           0           8           1\nCOX1      108343       65829      107741       94682\nCOX2       19148        2713       17947       10656\nCOX3       51441       24915       50029       47750\nCYTB       57844       34616       50587       51198\n\n\n\nCheck that the sample IDs match\nWhen creating the DESeq2 object, DESeq2 assumes that sample IDs in both tables match and are provided in the same order. Let’s make sure this is indeed the case:\n\nall(row.names(meta) == colnames(count_mat))\n\n[1] TRUE\n\n\n\n\n\n\n2.3 Create the DESeq2 object\nWe will create the DESeq2 object using the function DESeqDataSetFromMatrix(), which we will provide with three arguments corresponding to the components discussed above:\n\nThe metadata with argument colData.\nThe count data with argument countData.\nThe statistical design for the DE analysis with argument design. For now, we will specify ~1, which effectively means “no design” — we will change this before the actual DE analysis.\n\n\n# (`dds` is a name commonly used for DESeq2 objects, short for \"DESeq Data Set\")\ndds &lt;- DESeqDataSetFromMatrix(\n  colData = meta,\n  countData = count_mat,\n  design = ~ 1\n  )\n\nconverting counts to integer mode\n\n\nBefore we will run the differential expression analysis, though, we will do a bit of exploratory data analysis using our dds object."
  },
  {
    "objectID": "lab2.html#exploratory-data-analysis",
    "href": "lab2.html#exploratory-data-analysis",
    "title": "Lab part II: differential expression analysis",
    "section": "3 Exploratory Data Analysis",
    "text": "3 Exploratory Data Analysis\n\n3.1 Our count matrix\nWhat are the number of rows (=number of genes) and columns (=number of samples) of our count matrix?\n\ndim(count_mat)\n\n[1] 18855    22\n\n\nHow many genes have total (= across all samples) counts that are non-zero?\n\nnrow(count_mat[rowSums(count_mat) &gt; 0, ])\n\n[1] 17788\n\n\n\n\n Exercise: gene counts\n\nHow many genes have total counts of at least 10?\n\n\n\nClick to see the solution\n\n\nnrow(count_mat[rowSums(count_mat) &gt;= 10, ])\n\n[1] 16682\n\n\n\n\nBonus: How many genes have mean counts of at least 10?\n\n\n\nClick to see the solution\n\n\n# Now we need to divide by the number of samples, which is the number of columns,\n# which we can get with 'ncol'\nnrow(count_mat[rowSums(count_mat) / ncol(count_mat) &gt;= 10, ])\n\n[1] 12529\n\n\n\n\n\nHow do the “library sizes”, i.e. the summed per-sample gene counts, compare across samples?\n\ncolSums(count_mat)\n\nERR10802863 ERR10802864 ERR10802865 ERR10802866 ERR10802867 ERR10802868 \n   24297245    17177436    22745445    26849403    21471477    17506262 \nERR10802869 ERR10802870 ERR10802871 ERR10802874 ERR10802875 ERR10802876 \n   24299398    25490128    26534405    22194841    18927885    28804150 \nERR10802877 ERR10802878 ERR10802879 ERR10802880 ERR10802881 ERR10802882 \n    9498249    14807513    20667093    23107463    17545375    19088206 \nERR10802883 ERR10802884 ERR10802885 ERR10802886 \n   21418234    19420046    24367372    25452228 \n\n\n\n Bonus exercise: nicer counts\nThat’s not so easy to read / interpret. Can you instead get these numbers in millions, rounded to whole numbers, and sorted from low to high?\n\n\nClick to see the solution\n\n\nsort(round(colSums(count_mat) / 1000000))\n\nERR10802877 ERR10802878 ERR10802864 ERR10802868 ERR10802881 ERR10802875 \n          9          15          17          18          18          19 \nERR10802882 ERR10802884 ERR10802867 ERR10802879 ERR10802883 ERR10802874 \n         19          19          21          21          21          22 \nERR10802865 ERR10802880 ERR10802863 ERR10802869 ERR10802885 ERR10802870 \n         23          23          24          24          24          25 \nERR10802886 ERR10802866 ERR10802871 ERR10802876 \n         25          27          27          29 \n\n\n\n\n\n\n\n3.2 Principal Component Analysis (PCA)\nWe will run a PCA to examine overall patterns of (dis)similarity among samples, helping us answer questions like:\n\nDo the samples cluster by treatment (infection status) and/or time point?\nWhich of these two variables has a greater effect on overall patterns of gene expression?\nIs there an overall interaction between these two variables?\n\nFirst, normalize the count data to account for differences in library size among samples and “stabilize” the variance among genes4:\n\ndds_vst &lt;- varianceStabilizingTransformation(dds)\n\n\n\n\n\n\n\nThe authors of the study did this as well:\n\n\n\n\nWe carried out a Variance Stabilizing Transformation (VST) of the counts to represent the samples on a PCA plot.\n\n\n\n\nNext, run and plot the PCA with a single function call, plotPCA from DESeq2:\n\n# With 'intgroup' we specify the variables (columns) to color samples by\nplotPCA(dds_vst, intgroup = c(\"time\", \"treatment\"))\n\n\n\n\n\n\n\n\n\n\n Exercise: PCA\n\nBased on your PCA plot, try to answer the three questions asked at the beginning of this PCA section.\nHow does our plot compare to the PCA plot in the paper (Figure 1), in terms of the conclusions you just drew in the previous exercise.\n\n\n\nClick to see the paper’s Figure 1\n\n\n\n\n\n\nBonus: Compare the PCA plot with different numbers of included genes (Hint: figure out how to do so by looking at the help by running ?plotPCA).\nBonus: Customize the PCA plot — e.g. can you “separate” treatment and time point (different shapes for one variable, and different colors for the other), like in Fig. 1 of the paper?\n\n\n\nClick to see some hints for PCA plot customization\n\nTo expand on the point of the exercise: in the plot we made above, each combination of time point and treatment has a distinct color — it would be better to use point color only to distinguish one of the variables, and point shape to distinguish the other variable (as was also done in the paper’s Fig. 1).\nTo be able to customize the plot properly, we best build it from scratch ourselves, rather than using the plotPCA function. But then how do we get the input data in the right shape?\nA nice trick is that we can use returnData = TRUE in the plotPCA function, to get plot-ready formatted data instead of an actual plot:\n\npca_df &lt;- plotPCA(dds_vst, ntop = 500,\n                  intgroup = c(\"time\", \"treatment\"), returnData = TRUE)\n\nWith that pca_df dataframe in hand, it will be relatively straightforward to customize the plot, if you know some ggplot2.\n\n\n\nClick to see a possible solution\n\nFirst, we’ll get the data in the right format, as explained in the hint:\n\npca_df &lt;- plotPCA(dds_vst, ntop = 500,\n                  intgroup = c(\"time\", \"treatment\"), returnData = TRUE)\n\nSecond, we’ll extract and store the percentage of variance explained by different principal components, so we can later add this information to the plot:\n\npct_var &lt;- round(100 * attr(pca_df, \"percentVar\"), 1)\npct_var\n\n[1] 85.3  3.1\n\n\nNow we can make the plot:\n\nggplot(pca_df,\n       aes(x = PC1, y = PC2, color = treatment, shape = time)) +\n  geom_point(size = 5) +\n  labs(x = paste0(\"PC1 (\", pct_var[1], \"%)\"),\n       y = paste0(\"PC2 (\", pct_var[2], \"%)\")) +\n  scale_color_brewer(palette = \"Dark2\", name = \"Infection status\") +\n  scale_shape(name = \"Time points\") +\n  theme_bw() +\n  theme(panel.grid.minor = element_blank())"
  },
  {
    "objectID": "lab2.html#differential-expression-de-analysis",
    "href": "lab2.html#differential-expression-de-analysis",
    "title": "Lab part II: differential expression analysis",
    "section": "4 Differential Expression (DE) analysis",
    "text": "4 Differential Expression (DE) analysis\n\n4.1 Figuring out how to do the analysis\nFirst, let’s see how the DE analysis was done in the paper:\n\nThen, we used the DESeq2 package (Love et al., 2014) to perform the differential gene expression analysis comparing: (i) P. relictum-infected mosquitoes vs. controls, (ii) P. cathemerium-infected mosquitoes vs. controls, and (iii) P. relictum-infected mosquitoes vs. P. cathemerium-infected mosquitoes.\n\nThis is not terribly detailed and could be interpreted in a couple of different ways. For example, they may have compared infection statuses by ignoring time points or by controlling for time points (and there are different ways to do the latter).\nIgnoring time would mean analyzing the full dataset (all time points) while only using the infection status as an independent variable, i.e. the design ~treatment.\n\n\n Given the PCA results, do you think that ignoring the time variable is a good idea? (Click for the answer)\n\nNo: the time variable clearly has a large effect on overall patterns of gene expression, in fact more so than the treatment..\n\nControlling for time can be done in two ways:\n\nA two-factor analysis: ~ time + treatment.\nPairwise comparisons between each combination of time and treatment (we’ll see below how we can do that).\n\nIf we take a look at Table 1 with the DE results, it will become clearer how they did their analysis:\n\n\n\n\n\n\n\n How do you interpret this: did they run pairwise comparisons or a two-factor model? (Click for the answer)\n\nIt looks like they performed pairwise comparisons between each combination of time and treatment.\n\n\nThat brings us a step closer, but pairwise comparisons with &gt;1 independent variable can (also!) be done in two ways:\n\nAfter subsetting the dataset to each combination of time and treatment.\nAfter creating a single, combined independent variable that is a combination of time and treatment.\n\nThe latter method is the more common one, and is what we will do below5.\n\n\n\n4.2 Setting the statistical design\nWe will now create a new variable that is a combination of treatment and time, and call it group:\n\n# Create a combined variable called 'group':\ndds$group &lt;- factor(paste(dds$treatment, dds$time, sep = \"_\"))\n\n# Which unique values does 'group' have, and how many samples are in each?\ntable(dds$group)\n\n\ncathemerium_10dpi cathemerium_24hpi     control_10dpi     control_24hpi \n                4                 3                 4                 3 \n   relictum_10dpi    relictum_24hpi \n                4                 4 \n\n\nNext, we set the analysis design:\n\n# Note: the symbol before 'group' is a tilde, ~ \ndesign(dds) &lt;- ~ group\n\nNow we’re ready to run the DE analysis!\n\n\n\n4.3 Running the DE analysis\nWhile we had to do a lot of prep to get to this stage, actually running the DE analysis is very simple:\n\n# We are assigning the output back to the same `dds` object - the DE results are added to it\ndds &lt;- DESeq(dds)\n\nestimating size factors\n\n\nestimating dispersions\n\n\ngene-wise dispersion estimates\n\n\nmean-dispersion relationship\n\n\nfinal dispersion estimates\n\n\nfitting model and testing\n\n\nThe DESeq() function is a wrapper that performs three steps (functions) consecutively:\n\nestimateSizeFactors() — “Normalization” by library size and composition.\nestimateDispersions() — Estimate gene-wise dispersion (variance in counts).\nnbinomWaldTest(ddsObj) — Fit the negative binomial GLM and calculate test statistics\n\nA key thing to understand is that above, DESeq2 automatically performed pairwise comparisons between each of the (6) levels of the group variable. This means that for any individual gene, it tested whether the gene is differentially expressed separately for each of these pairwise comparisons."
  },
  {
    "objectID": "lab2.html#extracting-the-de-results",
    "href": "lab2.html#extracting-the-de-results",
    "title": "Lab part II: differential expression analysis",
    "section": "5 Extracting the DE results",
    "text": "5 Extracting the DE results\nDESeq2 stores the results as a separate table for each pairwise comparison, and now, we’ll extract one of these.\n\n5.1 The results table\nWe can extract the results for one pairwise comparison (which DESeq2 refers to as a contrast) at a time, by specifying it with the contrast argument as a vector of length 3:\n\nThe focal independent variable (here, group)\nThe first (reference) level of the independent variable (in the example below, relictum_24hpi)\nThe second level of the independent variable (in the example below, control_24hpi)\n\n\nfocal_contrast &lt;- c(\"group\", \"relictum_24hpi\", \"control_24hpi\")\nres_rc24 &lt;- results(dds, contrast = focal_contrast)\n\nhead(res_rc24)\n\nlog2 fold change (MLE): group relictum_24hpi vs control_24hpi \nWald test p-value: group relictum_24hpi vs control_24hpi \nDataFrame with 6 rows and 6 columns\n       baseMean log2FoldChange     lfcSE      stat    pvalue      padj\n      &lt;numeric&gt;      &lt;numeric&gt; &lt;numeric&gt; &lt;numeric&gt; &lt;numeric&gt; &lt;numeric&gt;\nATP6  7658.0445      -0.416305  0.609133 -0.683438 0.4943300  0.776172\nATP8     4.9196      -1.311116  1.388811 -0.944057 0.3451406        NA\nCOX1 75166.8670      -0.590935  0.282075 -2.094958 0.0361747  0.208045\nCOX2  7807.1848      -0.610152  0.578401 -1.054893 0.2914743  0.615249\nCOX3 41037.7359      -0.400173  0.251760 -1.589498 0.1119479  0.388880\nCYTB 36916.6130      -0.501653  0.261927 -1.915242 0.0554617  0.266528\n\n\nWhat do the columns in this table contain?\n\nbaseMean: Mean expression level across all samples.\nlog2FoldChange: The “log2-fold change” of gene counts between the compared levels.\nlfcSE: The uncertainty in terms of the standard error (SE) of the log2-fold change estimate.\nstat: The value for the Wald test’s test statistic.\npvalue: The uncorrected p-value from the Wald test.\npadj: The multiple-testing corrected p-value (i.e., adjusted p-value).\n\n\n\n\n\n\n\nMultiple testing correction\n\n\n\nBecause we are testing significance for many genes, we need to correct for multiple testing. DESeq2 uses the Benjamini-Hochberg False Discovery Rate (FDR) correction. For more info, see this StatQuest video.\n\n\n\n\n\n\n\n\nLog2-fold changes (LFCs)\n\n\n\nIn RNA-seq, log2-fold changes (LFCs) are the standard way of representing the magnitude (effect size) of expression level differences between two groups of interest. With A and B being the compared sample groups, the LFC is calculated as:\nlog2(mean of A / mean of B)\nDue the log-transformation, the LFC also increase more slowly than a raw fold-change:\n\nAn LFC of 1 indicates a 2-fold difference\nAn LFC of 2 indicates a 4-fold difference\nAn LFC of 3 indicates a 8-fold difference\n\nA nice property of LFC is that decreases and increases in expression are expressed symmetrically:\n\nAn LFC of 1 means that group A has a two-fold higher expression that group B\nAn LFC of -1 means that group A has a two-fold lower expression that group B\n\n\n\n\n\n Exercise: Log-fold changes\nBased on the above, or your knowledge of log-transformations, what do you expect the following to return:\n\n# In the context of a LFC, these 2 numbers would be mean expression levels in 2 groups\nlog2(8 / 2)\nlog2(2 / 8)\n\n\n\nClick to see the solution\n\n\nA fold-change of 4 (8/2) is a LFC of 2:\n\n\nlog2(8 / 2)\n\n[1] 2\n\n\n\nA fold-change of 0.25 (2/8) is a LFC of -2:\n\n\nlog2(2 / 8)\n\n[1] -2\n\n\n\n\n\n\n\n5.2 Numbers of Differentially Expressed Genes (DEGs)\nHow many adjusted p-values were less than 0.05 (i.e., significant)?\n\n# (We need 'na.rm = TRUE' because some p-values are 'NA')\n# (If we don't remove NAs from the calculation, sum() will just return NA)\nsum(res_rc24$padj &lt; 0.05, na.rm = TRUE)\n\n[1] 801\n\n\nSo, we have 801 Differentially Expressed Genes (DEGs) for this specific pairwise comparison.\n\n\n Exercise: DEGs\nThe paper’s Table 1 (which we saw above) reports the number of DEGs for a variety of comparisons.\n\nHow does the number of DEGs we just got compare to what they found in the paper for this comparison?\nThe table also reports numbers of up- and downregulated genes separately. Can you find this out for our DEGs?\n\n\n\nClick to see the solution\n\n\nSolution using tidyverse/dplyr:\n\n\n# First we need to convert the results table into a regular data frame\nas.data.frame(res_rc24) |&gt;\n  # Then we only select the rows/genes that are significant\n  filter(padj &lt; 0.05) |&gt;\n  # If we run count() on a logical test, we get the nrs. that are FALSE v. TRUE\n  dplyr::count(log2FoldChange &gt; 0)\n\n  log2FoldChange &gt; 0   n\n1              FALSE 616\n2               TRUE 185\n\n\n\nSolution using base R:\n\n\n# Down-regulated (relictum &lt; control):\nsum(res_rc24$log2FoldChange &lt; 0 & res_rc24$padj &lt; 0.05, na.rm = TRUE)\n\n[1] 616\n\n# Up-regulated (relictum &gt; control):\nsum(res_rc24$log2FoldChange &gt; 0 & res_rc24$padj &lt; 0.05, na.rm = TRUE)\n\n[1] 185\n\n\n\n\n\n\nBonus: The table also reports the number of DEGs with an absolute LFC &gt; 1. Can you find this out for our DEGs?\n\n\n\nClick to see the solution\n\n\nSolution using tidyverse/dplyr:\n\n\n# First we need to convert the results table into a regular data frame\nas.data.frame(res_rc24) |&gt;\n  # Then we only select the rows/genes that are significant\n  filter(padj &lt; 0.05, abs(log2FoldChange) &gt; 1) |&gt;\n  # If we run count() on a logical test, we get the nrs. that are FALSE v. TRUE\n  dplyr::count(log2FoldChange &gt; 0)\n\n  log2FoldChange &gt; 0   n\n1              FALSE 159\n2               TRUE  49\n\n\n\nSolution using base R:\n\n\n# Down-regulated (relictum &lt; control):\nsum(res_rc24$log2FoldChange &lt; -1 & res_rc24$padj &lt; 0.05, na.rm = TRUE)\n\n[1] 159\n\n# Up-regulated (relictum &gt; control):\nsum(res_rc24$log2FoldChange &gt; 1 & res_rc24$padj &lt; 0.05, na.rm = TRUE)\n\n[1] 49\n\n\n\n\nBonus: Extract the results for one or more other contrasts in the table, and compare the results."
  },
  {
    "objectID": "lab2.html#visualizing-the-de-results",
    "href": "lab2.html#visualizing-the-de-results",
    "title": "Lab part II: differential expression analysis",
    "section": "6 Visualizing the DE results",
    "text": "6 Visualizing the DE results\nTo practice with visualization of the differential expression results, we will create a few plots for the results for the relictum_24hpi vs. control_24hpi comparison, which we extracted above.\n\n\n6.1 Volcano plot\nFor a nice overview of the results, we can create a so-called “volcano plot” using the EnhancedVolcano() function from the package of the same name (see here for a “vignette”/tutorial):\n\nEnhancedVolcano(\n  toptable = res_rc24,      # DESeq2 results to plot   \n  title = \"relictum vs. control at 24 hpi\",\n  x = \"log2FoldChange\",     # Plot the log2-fold change along the x-axis\n  y = \"padj\",               # Plot the p-value along the y-axis\n  lab = rownames(res_rc24), # Use the rownames for the gene labels (though see below)\n  labSize = 0               # Omit gene labels for now\n  )\n\n\n\n\n\n\n\n\n\n Bonus exercise: Volcano plots\nThe EnhancedVolcano() function by default adds gene IDs to highly significant genes, but above, we turned off gene name labeling by setting labSize = 0. I did this because the default p-value cut-off for point labeling is 1e-5 and in this case, that would make the plot quite busy with gene labels. We might want to try a plot with a stricter p-value cut-off that does show the gene labels.\n\nPlay around with the p-value cut-off and the labeling to create a plot you like.\nCheck the vignette, or the help page (accessed by running ?EnhancedVolcano) to see how you can do this.\n\n\n\nClick for an example\n\n\nEnhancedVolcano(\n  toptable = res_rc24,      \n  title = \"relictum vs. control at 24 hpi\",\n  x = \"log2FoldChange\",     \n  y = \"padj\",             \n  lab = rownames(res_rc24), \n  labSize = 4,               # Now we will show the gene labels\n  pCutoff = 10e-10,          # Modify the p-value cut-off\n  subtitle = NULL,           # I'll also remove the silly subtitle\n  caption = NULL,            # ... and the caption\n  )\n\n\n\n\n\n\n\n\n\n\nFigure out the identity of the abovementioned log2-fold change outlier.\n(You can do so either by labeling it in the plot, or by filtering the res_rc24 table.)\n\n\n\nClick for the solution for how to lab it in the plot\n\n\n\nEnhancedVolcano(\n  toptable = res_rc24,      \n  title = \"relictum vs. control at 24 hpi\",\n  x = \"log2FoldChange\",     \n  y = \"padj\",             \n  lab = rownames(res_rc24), \n  labSize = 4,               \n  pCutoff = 0.05,            # Modify the p-value cut-off\n  FCcutoff = 20,             # Modify the LFC cut-off\n  )\n\nWarning: Removed 1 row containing missing values or values outside the scale range\n(`geom_vline()`).\n\n\n\n\n\n\n\n\n\n\n\n\nClick for the solution for how to find it in the results table\n\n\n\nas.data.frame(res_rc24) |&gt; filter(log2FoldChange &gt; 20)\n\n              baseMean log2FoldChange    lfcSE     stat       pvalue\nLOC120413430  7.540043       24.46898 5.397990 4.532979           NA\nLOC120431476 39.720375       23.01445 5.301369 4.341228 1.416886e-05\n                     padj\nLOC120413430           NA\nLOC120431476 0.0008584398\n\n\n(Interestingly, there’s a second gene with a LFC &gt; 20 that we hadn’t seen in the plot, because it has NA as the pvalue and padj. See the section “Extra info: NA values in the results table” in the Appendix for why p-values can be set to NA.)\n\n\n\n\n\n6.2 Plot specific genes\nWe can also create plots of expression levels for individual genes. That is especially interesting for genes with highly significant differential expression. So let’s plot the most highly significant DEG.\nFirst, let’s create a vector with most highly significant DEGs, which we’ll use again for the heatmap below.\n\ntop25_DE &lt;- row.names(res_rc24[order(res_rc24$padj)[1:25], ])\n\ntop25_DE\n\n [1] \"LOC120423768\" \"LOC120423767\" \"LOC120414587\" \"LOC128092307\" \"LOC120431154\"\n [6] \"LOC120427827\" \"LOC120415152\" \"LOC120422735\" \"LOC120431739\" \"LOC120431733\"\n[11] \"LOC120428214\" \"LOC120427588\" \"LOC120415540\" \"LOC120415522\" \"LOC120429000\"\n[16] \"LOC120414889\" \"LOC120413491\" \"LOC120414802\" \"LOC120423826\" \"LOC120429211\"\n[21] \"LOC120425480\" \"LOC120431003\" \"LOC120421894\" \"LOC120423819\" \"LOC128093166\"\n\n\nDESeq2 has a plotting function but the plot is not very good. We will still use that function but just to quickly extract the counts for our gene of interest in the right format for plotting, using returnData = TRUE:\n\nfocal_gene_counts &lt;- plotCounts(\n  dds,\n  gene = top25_DE[1],\n  intgroup = c(\"time\", \"treatment\"),\n  returnData = TRUE\n  )\n\nhead(focal_gene_counts)\n\n                 count  time   treatment\nERR10802863 1543.81532 24hpi     control\nERR10802864 2279.03704 24hpi cathemerium\nERR10802865   25.42295 24hpi    relictum\nERR10802866 1105.75009 24hpi     control\nERR10802867 1199.28425 24hpi cathemerium\nERR10802868   32.14394 24hpi    relictum\n\n\nNow, we can make the plot:\n\nggplot(focal_gene_counts,\n       # Treatment along the x-axis, gene counts along the y, color by treatment:\n       aes(x = treatment, y = count, fill = treatment)) +\n  # Plot separate \"facets\" with the different time points\n  facet_wrap(vars(time)) +\n  # Add a boxplot with a partly transparaent (alpha) color:\n  geom_boxplot(alpha = 0.5, outlier.shape = NA) +\n  # _And_ add individual points:\n  geom_point(size = 4, shape = 21,\n             position = position_jitter(w = 0.1, h = 0)) +\n  # Plot styling (e.g., we don't need a legend)\n  theme_bw() +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\n\n\n\n Exercise: Single-gene plots\n\nPlot one or a few more of the top-DE genes. Do they have similar expression patterns across treatment and time points as the first one?\n\n\n\nBonus: Plot the gene with the very high LFC value that we saw when making the volcano plot. How would you interpret this?\n\n\n\nClick for the solution\n\n\nfocal_gene_counts &lt;- plotCounts(\n  dds,\n  gene = \"LOC120431476\",\n  intgroup = c(\"time\", \"treatment\"),\n  returnData = TRUE\n  )\n\nggplot(focal_gene_counts, aes(x = treatment, y = count, fill = treatment)) +\n  geom_boxplot(alpha = 0.5, outlier.shape = NA) +\n  geom_point(size = 4, shape = 21, position = position_jitter(w = 0.1, h = 0)) +\n  facet_wrap(vars(time)) +\n  theme_bw() +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\nWow! It looks like in every single time + treatment combinations, all but one (or in one case, two) of the samples have zero expression, but there are several extreme outliers.\nOur focal comparison at 24hpi (left panel/facet), and comparing control vs relictum: so it looks like the difference between these two groups is solely due to the one outlier in relictum. Nevertheless, even the multiple-testing corrected p-value (padj) is significant for this gene:\n\nas.data.frame(res_rc24) |&gt;\n  rownames_to_column(\"gene\") |&gt;\n  filter(gene == \"LOC120431476\")\n\n          gene baseMean log2FoldChange    lfcSE     stat       pvalue\n1 LOC120431476 39.72038       23.01445 5.301369 4.341228 1.416886e-05\n          padj\n1 0.0008584398\n\n\nSo, we have to be careful with talking our statistical results at face value, and need to visualize important genes!\n\n\n\n\n\n\n\nOutliers!\n\n\n\nYou may want to check out the solution to the previous exercise, even if you don’t get around to doing it yourself."
  },
  {
    "objectID": "lab2.html#in-closing",
    "href": "lab2.html#in-closing",
    "title": "Lab part II: differential expression analysis",
    "section": "7 In Closing",
    "text": "7 In Closing\nToday, you have performed several steps in the analysis of gene counts that result from a typical RNA-seq workflow. Specifically, you have:\n\nCreated a DESEq2 object from the gene count data and the experiment’s metadata\nPerformed exploratory data analysis including a PCA\nRan a Differential Expression (DE) analysis with DESeq2\nExtracted, interpreted, and visualized the DE results\n\n\nNext steps\nTypical next steps in such an analysis include:\n\nExtracting, comparing, and synthesizing DE results across all pairwise comparisons (this would for example allow us to make the upset plot in Figure 2 of the paper)\nFunctional enrichment analysis with Gene Ontology (GO) terms, as done in the paper, and/or with KEGG pathways and other functional gene grouping systems."
  },
  {
    "objectID": "lab2.html#appendix",
    "href": "lab2.html#appendix",
    "title": "Lab part II: differential expression analysis",
    "section": "8 Appendix",
    "text": "8 Appendix\n\n8.1 Heatmaps\nRather than plotting expression levels for many individual genes, we can create “heatmap” plots to plot dozens (possibly even hundreds) of genes at once.\nWe will create heatmaps with the pheatmap function, and let’s make a heatmap for the top-25 most highly significant DEGs for our focal contrast.\nUnlike with some of the functions we used before, we unfortunately can’t directly use our DESeq2 object, but we have to extract and subset the count matrix, and also pass the metadata to the heatmap function:\n\n# We need a normalized count matrix, like for the PCA\n# We can simply extract the matrix from the normalized dds object we created for the PCA\nnorm_mat &lt;- assay(dds_vst)\n\n# In the normalized count matrix, select only the genes of interest\n# We'll reuse the 'top25_DE' vector that we created for the individual gene plots\nnorm_mat_sel &lt;- norm_mat[match(top25_DE, rownames(norm_mat)), ]\n\n# Sort the metadata\nmeta_sort &lt;- meta |&gt;\n  arrange(treatment, time) |&gt;\n  select(treatment, time)\n\nNow we can create the plot:\n\npheatmap(\n  norm_mat_sel,\n  annotation_col = meta_sort,  # Add the metadata\n  cluster_cols = FALSE,        # Don't cluster samples (=columns, cols)\n  show_rownames = FALSE,       # Don't show gene names\n  scale = \"row\",               # Perform z-scaling for each gene\n  )\n\n\n\n\n\n\n\n\nNotes on the code and plot above:\n\nThe z-scaling with scale = will make sure we can compare genes with very different expression levels: after all, we’re interested in relative expression levels across samples/sample groups.\npheatmap will by default perform hierarchical clustering both at the sample (col) and gene (row) level, such that more similar samples and genes will appear closer to each other. Above, we turned clustering off for samples, since we want to keep them in their by-group order.\n\n\n\n Bonus exercise: heatmaps\nMake a heatmap with the top-25 most-highly expressed genes (i.e., genes with the highest mean expression levels across all samples).\n\n\nClick for a hint: how to get that top-25\n\n\ntop25_hi &lt;- names(sort(rowMeans(norm_mat), decreasing = TRUE)[1:25])\n\n\n\n\nClick for the solution\n\n\n# In the normalized count matrix, select only the genes of interest\nnorm_mat_sel &lt;- norm_mat[match(top25_hi, rownames(norm_mat)), ]\n\n# Sort the metadata\nmeta_sort &lt;- meta |&gt;\n  arrange(treatment, time) |&gt;\n  select(treatment, time)\n\n# Create the heatmap\npheatmap(\n  norm_mat_sel,\n  annotation_col = meta_sort,\n  cluster_cols = FALSE,\n  show_rownames = FALSE,\n  scale = \"row\"\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\n8.2 NA values in the DESeq2 results table\nSome values in the DESeq2 results table can be set to NA for one of the following reasons:\n\nIf a gene contains a sample with a count outlier, both the p-value and adjusted p-value will be set to NA. (DESeq2 performs outlier detection using Cook’s distance.)\nIf all samples have zero counts for a given gene, the baseMean column will be zero, and the log2-fold change estimates, p-value and adjusted p-value will all be set to NA.\nDESeq2 also automatically filters genes with a low mean count in the sense that it does not include them in the multiple testing correction. Therefore, in such cases, the p-value will not be NA, but the adjusted p-value will be.\nBecause we have very low power to detect differential expression for such low-count genes, it is beneficial to remove them prior to the multiple testing correction: that way, the correction becomes less severe for the remaining genes.\n\nLet’s see how many genes have NA p-values:\n\n# Number of genes with NA p-value:\nsum(is.na(res_rc24$pvalue))\n\n[1] 1124\n\n# As a proportion of the total number of genes in the test:\nsum(is.na(res_rc24$pvalue)) / nrow(res_rc24)\n\n[1] 0.05961283\n\n\nAnd NA adjusted p-values:\n\n# Number of genes with NA p-value:\nsum(is.na(res_rc24$padj))\n\n[1] 7283\n\n# As a proportion of the total number of genes in the test:\nsum(is.na(res_rc24$padj)) / nrow(res_rc24)\n\n[1] 0.3862636\n\n\n\n\n\n8.3 Exporting the results\nTo save the DE results tables, you can for example use the write_tsv() function. You could open the resulting file in Excel for further exploration.\n\n# Create the output directory, if necessary:\ndir.create(\"results/DE\", recursive = TRUE, showWarnings = FALSE)\n\n# Write the \nwrite_tsv(as.data.frame(res_rc24), \"results/DE/resultsres_rc24.tsv\")"
  },
  {
    "objectID": "lab2.html#footnotes",
    "href": "lab2.html#footnotes",
    "title": "Lab part II: differential expression analysis",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nAn older pipe, which requires loading an R package to work↩︎\nThe new base R pipe that does not require a package↩︎\nAnd even for more basic tasks, it is common to use packages that are preferred over the functionality that is by default available in R, like in the case of plotting.↩︎\nSpecifically, the point is to remove the dependence of the variance in expression level on its mean, among genes↩︎\nI can’t tell from the paper which method they used↩︎"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "HCS7004-SP24",
    "section": "",
    "text": "Schedule for today\n\n\n\n\n1:50-2:45 pm — Lecture (slides)\n3:00-3:55 pm — Lab part I: Running nf-core’s rnaseq workflow\n4:00-4:50 pm — Lab part II: Differential expression analysis\n\n\n\n\n\n\n Back to top"
  }
]